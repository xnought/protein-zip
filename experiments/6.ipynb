{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_PDB = \"../data/A.pdb\"\n",
    "data = None\n",
    "with open(A_PDB, \"r\") as in_file:\n",
    "\tdata = in_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb(string: str, k = 1024):\n",
    "\treturn len(string) / (k*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I want to parse the string to read the unique characters in the file\n",
    "def char_frequencies(string: str) -> dict[str, int]:\n",
    "\tfreqs = {}\n",
    "\tfor char in string:\n",
    "\t\tif char not in freqs:\n",
    "\t\t\tfreqs[char] = 0\n",
    "\t\telse:\n",
    "\t\t\tfreqs[char] += 1\n",
    "\treturn freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffNode():\n",
    "\tdef __init__(self, freq: int, lchild: \"HuffNode\" = None, rchild: \"HuffNode\" = None):\n",
    "\t\tself.freq = freq\n",
    "\t\tself.lchild = lchild\n",
    "\t\tself.rchild = rchild\n",
    "\tdef str(self):\n",
    "\t\treturn f\"({self.lchild.str()},{self.rchild.str()})\"\n",
    "\tdef __repr__(self):\n",
    "\t\treturn self.__class__.__name__ + \"(\" + self.__dict__.__str__() + \")\"\n",
    "\n",
    "class HuffLeaf(HuffNode):\n",
    "\tdef __init__(self, freq: int, char: str):\n",
    "\t\tsuper().__init__(freq)\n",
    "\t\tself.char = char\n",
    "\tdef str(self):\n",
    "\t\treturn f\"'{self.char}'\"\n",
    "\n",
    "def is_leaf(node: HuffNode):\n",
    "\treturn node.__class__ is HuffLeaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heapify, heappop, heappush\n",
    "\n",
    "def node_to_heapq_format(node: HuffNode):\n",
    "\treturn (node.freq, node) # high frequency ones should come up first\n",
    "\n",
    "\n",
    "def heapq_format_to_node(heapq_item: tuple[int, HuffNode]):\n",
    "\treturn heapq_item[1] # (priority, node)[1] selects node\n",
    "\n",
    "class HuffQueue():\n",
    "\tdef __init__(self, freqs: dict[str, int]):\n",
    "\t\tself.priority_queue = []\n",
    "\t\theapify(self.priority_queue)\n",
    "\t\t\n",
    "\t\t# add all the leaves (characters) first\n",
    "\t\tfor c, f in freqs.items():\n",
    "\t\t\tself.push(HuffLeaf(freq=f, char=c))\n",
    "\n",
    "\tdef pop(self) -> HuffNode:\n",
    "\t\treturn heapq_format_to_node(heappop(self.priority_queue))\n",
    "\n",
    "\tdef push(self, new_node: HuffNode):\n",
    "\t\theappush(self.priority_queue, node_to_heapq_format(new_node))\n",
    "\t\n",
    "\tdef peak(self) -> HuffNode:\n",
    "\t\treturn heapq_format_to_node(self.priority_queue[0])\n",
    "\t\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.priority_queue)\n",
    "\t\n",
    "\tdef __repr__(self) -> str:\n",
    "\t\treturn f\"HuffQueue(len={len(self)}, top={self.peak()})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huffman_code(freqs: dict[str, int]) -> HuffNode:\n",
    "    \"\"\"Returns the root node of the tree\"\"\"\n",
    "\n",
    "    q = HuffQueue(freqs)\n",
    "    while len(q) > 1:\n",
    "        # pop two smallest nodes, they are now the bottom of the tree\n",
    "        child_a, child_b = q.pop(), q.pop()\n",
    "        parent = HuffNode(\n",
    "            freq=child_a.freq + child_b.freq, \n",
    "            lchild=child_a, \n",
    "            rchild=child_b\n",
    "        )\n",
    "        # push the nodes (almost think of merged) back into circulation\n",
    "        q.push(parent)\n",
    "\n",
    "    return q.pop() # return the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuffNode({'freq': -1, 'lchild': HuffNode({'freq': -1, 'lchild': HuffLeaf({'freq': -1, 'lchild': None, 'rchild': None, 'char': 'A'}), 'rchild': HuffLeaf({'freq': -1, 'lchild': None, 'rchild': None, 'char': 'V'})}), 'rchild': HuffNode({'freq': -1, 'lchild': HuffLeaf({'freq': -1, 'lchild': None, 'rchild': None, 'char': 'B'}), 'rchild': HuffNode({'freq': -1, 'lchild': HuffLeaf({'freq': -1, 'lchild': None, 'rchild': None, 'char': 'E'}), 'rchild': HuffLeaf({'freq': -1, 'lchild': None, 'rchild': None, 'char': 'F'})})})})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outer_comma(string: str):\n",
    "    \"\"\"\"Returns None on failure and an int when found\"\"\"\n",
    "    other = 0\n",
    "    for i, char in enumerate(string):\n",
    "        if other == 1 and char == \",\":\n",
    "            return i\n",
    "        \n",
    "        # if we encounter another paren, need to find its own matching pair\n",
    "        if char == \"(\":\n",
    "            other += 1\n",
    "        elif char == \")\":\n",
    "            other -= 1\n",
    "\n",
    "    return None\n",
    "    \n",
    "\n",
    "def parse_str_to_tree(string: str):\n",
    "    # split a string at the upperlevel comma like \"((a,b), c)\" would split into \"(a,b)\" and \"c\"\n",
    "    # i define the scope as anything inside the upper level parentheses\n",
    "    # recursively do\n",
    "    comma = outer_comma(string)\n",
    "    a, b = string[:comma], string[comma+1:]\n",
    "    b = b[:-1]\n",
    "    a = a[1:]\n",
    "    if a[0] != \"'\":\n",
    "        a = parse_str_to_tree(a)\n",
    "    else:\n",
    "        a = a[1]\n",
    "    if b[0] != \"'\":\n",
    "        b = parse_str_to_tree(b)\n",
    "    else:\n",
    "        b = b[1]\n",
    "    return a, b\n",
    "\n",
    "def read_huffman_tree(tree_str: str) -> HuffNode:\n",
    "    tuple_tree = parse_str_to_tree(tree_str)\n",
    "\n",
    "    def construct(node):\n",
    "        if isinstance(node, str):\n",
    "            return HuffLeaf(freq=-1, char=node)\n",
    "        return HuffNode(freq=-1, \n",
    "                 lchild=construct(node[0]),\n",
    "                 rchild=construct(node[1]))\n",
    "\n",
    "    return construct(tuple_tree)\n",
    "\n",
    "read_huffman_tree(\"(('A','V'),('B',('EPIC','F')))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def shallow_split(string: str, split_on=10):\n",
    "    locs = []\n",
    "    outer = 0\n",
    "    for i in range(len(string)):\n",
    "        char = string[i]\n",
    "        if char == 40:\n",
    "            outer += 1\n",
    "        elif char == 41:\n",
    "            outer -= 1\n",
    "        \n",
    "        if outer == 0 and char == split_on:\n",
    "            locs.append(i)\n",
    "    return locs\n",
    "\n",
    "def leaves_to_encoding(code: HuffNode):\n",
    "    # first find all the leaves\n",
    "    # I can travel down, constructing a string, then when I hit, add that string to the global dict\n",
    "    mapping = {}\n",
    "    def trav(node: HuffNode, bits):\n",
    "        if is_leaf(node):\n",
    "            mapping[node.char] = bits\n",
    "            return\n",
    "        trav(node.lchild, bits+\"0\")\n",
    "        trav(node.rchild, bits+\"1\")\n",
    "\n",
    "    trav(code, \"\")\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def encode_huff(code: HuffNode, original: str) -> str:\n",
    "    # iterate over each character in the original, and convert it to bits form by \n",
    "    # considering a right turn as 1 and a left turn as 0 in the tree and when I hit a leaf stop\n",
    "    # a conceptually easier way to think about this is starting from each leaf, going up and keeping track of how many it takes to go up to the top\n",
    "    # and encoding based on which side it was, then creating a map that we can easily translate\n",
    "    res = \"\"\n",
    "    mapping = leaves_to_encoding(code)\n",
    "    for char in original:\n",
    "        res += mapping[char]\n",
    "    return res\n",
    "\n",
    "def decode_huff(root: HuffNode, encoded: str)  -> str:\n",
    "    # iterate over the encoded bit string where left is 0 and right is 1\n",
    "    # if I hit a leaf, then that is the character and restart\n",
    "    cur_node = root\n",
    "    result = \"\"\n",
    "    for bit in encoded:\n",
    "        if bit == \"1\":\n",
    "            cur_node = cur_node.rchild\n",
    "        elif bit == \"0\":\n",
    "            cur_node = cur_node.lchild\n",
    "        else: \n",
    "            print(\"ERROR\")\n",
    "\n",
    "        if is_leaf(cur_node):\n",
    "            result += cur_node.char # this is the correct char\n",
    "            cur_node = root # go back to the root node\n",
    "\n",
    "    return result\n",
    "\n",
    "def bits_str_to_bytes(bits: str):\n",
    "    n = len(bits)\n",
    "    byte = bits[:n]\n",
    "    return int(byte, base=2).to_bytes(math.ceil(n/8))\n",
    "\n",
    "def bytes_to_bits_str(b: bytes, actual_length):\n",
    "    result = \"\"\n",
    "    for chunk in b:\n",
    "        result += f\"{chunk:08b}\"\n",
    "    return result[len(result) - actual_length:]\n",
    "\n",
    "class Huff:\n",
    "    @staticmethod\n",
    "    def encode(string: str) -> tuple[str, HuffNode]:\n",
    "        freqs = char_frequencies(string)\n",
    "        huffman_code = create_huffman_code(freqs)\n",
    "        encoded = encode_huff(huffman_code, string)\n",
    "        return encoded, huffman_code\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(code: HuffNode, encoded: str) -> str:\n",
    "        decoded = decode_huff(code, encoded)\n",
    "        return decoded\n",
    "\n",
    "def to_pz(pdb_file_name: str):\n",
    "    \"\"\".pz means [p]rotein [z]ip\"\"\"\n",
    "    data = None\n",
    "    with open(pdb_file_name, \"r\") as pdb_file:\n",
    "        data = pdb_file.read()\n",
    "\n",
    "    encoded_str, huffman_code = Huff.encode(data)\n",
    "    encoded = bits_str_to_bytes(encoded_str)\n",
    "\n",
    "    NL = \"\\n\".encode()\n",
    "    with open(\"../null/example.pz\", \"wb\") as pz_file:\n",
    "        # two numbers, character length the location of the start of the tree\n",
    "        num_chars = f\"{len(data)}\".encode() + NL\n",
    "\n",
    "        huffman_tree_str = huffman_code.str().encode() + NL\n",
    "        data_loc = f\"{len(huffman_tree_str) + len(num_chars)}\".encode() + NL\n",
    "\n",
    "        # header\n",
    "        pz_file.write(num_chars)\n",
    "        pz_file.write(data_loc)\n",
    "        # tree\n",
    "        pz_file.write(huffman_tree_str)\n",
    "        # data\n",
    "        pz_file.write(encoded)\n",
    "\n",
    "def from_pz(pz_filename=\"../null/example.pz\"):\n",
    "    with open(pz_filename, \"rb\") as pz_file:\n",
    "        bs = pz_file.read()\n",
    "        first_nl = bs.index(10)\n",
    "        second_nl = bs[first_nl+1:].index(10) + first_nl\n",
    "\n",
    "        chars = int(bs[:first_nl].decode())\n",
    "        data_loc = int(bs[first_nl:second_nl+1])\n",
    "        data_loc += len(str(data_loc)) + 1 # 1 for NL\n",
    "        encoding = bs[data_loc:]\n",
    "        tree_str = bs[second_nl+2:data_loc-1]\n",
    "\n",
    "        encoding = bytes_to_bits_str(encoding, chars) \n",
    "        tree_str = tree_str.decode()\n",
    "        huffman_code = read_huffman_tree(tree_str)\n",
    "        decoded = Huff.decode(huffman_code, encoding)\n",
    "        with open(\"../null/decoded.pdb\", \"w\") as pdb_file:\n",
    "            pdb_file.write(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"\n",
    "MODEL     1                                                                     \n",
    "ATOM      1  N   ASN A   1     -65.537  -3.389  11.278  1.00 44.93           N  \n",
    "ATOM      2  CA  ASN A   1     -64.535  -2.678  12.067  1.00 44.93           C  \n",
    "ATOM      3  C   ASN A   1     -63.123  -3.155  11.739  1.00 44.93           C  \n",
    "ATOM      4  CB  ASN A   1     -64.817  -2.839  13.562  1.00 44.93           C  \n",
    "ATOM      5  O   ASN A   1     -62.727  -4.253  12.133  1.00 44.93           O  \n",
    "ATOM      6  CG  ASN A   1     -65.657  -1.708  14.123  1.00 44.93           C  \n",
    "ATOM      7  ND2 ASN A   1     -66.129  -1.873  15.353  1.00 44.93           N  \n",
    "ATOM      8  OD1 ASN A   1     -65.882  -0.695  13.455  1.00 44.93           O  \n",
    "ATOM      9  N   CYS A   2     -62.653  -3.062  10.488  1.00 47.37           N  \n",
    "ATOM     10  CA  CYS A   2     -61.344  -3.432   9.960  1.00 47.37           C  \n",
    "ATOM     11  C   CYS A   2     -60.251  -2.544  10.541  1.00 47.37           C  \n",
    "ATOM     12  CB  CYS A   2     -61.335  -3.335   8.435  1.00 47.37           C  \n",
    "ATOM     13  O   CYS A   2     -60.208  -1.343  10.266  1.00 47.37           O  \n",
    "ATOM     14  SG  CYS A   2     -61.839  -4.859   7.606  1.00 47.37           S  \n",
    "ENDMDL                                                                          \n",
    "END                                                                             \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'HuffLeaf' and 'HuffLeaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mHuff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 77\u001b[0m, in \u001b[0;36mHuff.encode\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, HuffNode]:\n\u001b[1;32m     76\u001b[0m     freqs \u001b[38;5;241m=\u001b[39m char_frequencies(string)\n\u001b[0;32m---> 77\u001b[0m     huffman_code \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_huffman_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m encode_huff(huffman_code, string)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded, huffman_code\n",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m, in \u001b[0;36mcreate_huffman_code\u001b[0;34m(freqs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_huffman_code\u001b[39m(freqs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HuffNode:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the root node of the tree\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[43mHuffQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(q) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# pop two smallest nodes, they are now the bottom of the tree\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         child_a, child_b \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mpop(), q\u001b[38;5;241m.\u001b[39mpop()\n",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m, in \u001b[0;36mHuffQueue.__init__\u001b[0;34m(self, freqs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# add all the leaves (characters) first\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m freqs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 17\u001b[0m \t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHuffLeaf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m, in \u001b[0;36mHuffQueue.push\u001b[0;34m(self, new_node)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpush\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_node: HuffNode):\n\u001b[0;32m---> 23\u001b[0m \theappush(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriority_queue, node_to_heapq_format(new_node))\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'HuffLeaf' and 'HuffLeaf'"
     ]
    }
   ],
   "source": [
    "Huff.encode(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
